{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fd318f3-d07b-41b7-b3bb-d0d020000c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26090f89-82c6-4a86-89a8-018f1561321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01fb36df-82c6-4711-aff1-5067e9f8bacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./data/q1.csv\")\n",
    "df2 = pd.read_csv(\"./data/q2.csv\")\n",
    "df3 = pd.read_csv(\"./data/q3.csv\")\n",
    "df4 = pd.read_csv(\"./data/q4.csv\")\n",
    "df5 = pd.read_csv(\"./data/q5.csv\")\n",
    "df6 = pd.read_csv(\"./data/q6.csv\")\n",
    "df7 = pd.read_csv(\"./data/q7.csv\")\n",
    "df8 = pd.read_csv(\"./data/q8.csv\")\n",
    "df9 = pd.read_csv(\"./data/q9.csv\")\n",
    "df10 = pd.read_csv(\"./data/q10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "948465c1-fac2-4c14-8424-c0f072009382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30443, 11)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30443 entries, 0 to 3046\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Unnamed: 0         30443 non-null  int64  \n",
      " 1   song_id            30443 non-null  object \n",
      " 2   chart_position     30443 non-null  int64  \n",
      " 3   chart_date         30443 non-null  object \n",
      " 4   song               30443 non-null  object \n",
      " 5   performer          30443 non-null  object \n",
      " 6   time_on_chart      30443 non-null  int64  \n",
      " 7   consecutive_weeks  27315 non-null  float64\n",
      " 8   worst_position     30443 non-null  int64  \n",
      " 9   chart_debut        30443 non-null  object \n",
      " 10  lyrics             30443 non-null  object \n",
      "dtypes: float64(1), int64(4), object(6)\n",
      "memory usage: 2.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Concatenate to single column\n",
    "\n",
    "frames = [df1, df2, df3, df4, df5, df6, df7, df8, df9, df10]\n",
    "df = pd.concat(frames)\n",
    "print(df.shape)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f227678d-9b9b-44bb-9a20-8b095b670641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07594520907926289\n"
     ]
    }
   ],
   "source": [
    "# Calculate % not found in lyric search\n",
    "pct_not_found = (sum(df['lyrics'] == 'not found'))/len(df)\n",
    "print(pct_not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2143577-25a5-4650-aeb8-f64aff4fe42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA showed that there were some weird entries. such as the books beig returned for song lyrics. Who knows why. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b294bd88-7eb7-43d7-a7b0-9b5b68f8e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the number of lyrics for each song.\n",
    "res = {}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    lyric = row['lyrics']\n",
    "    Id = row['song_id']\n",
    "    res[Id] = lyric.split(\" \")\n",
    "\n",
    "#Result = pd.DataFrame(res).T\n",
    "#Result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adb85c40-b407-4aff-94d1-96f740444f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "string.punctuation\n",
    "\n",
    "def remove_punct(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7e801b4-858b-4756-8746-ab963911fffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lyrics_clean'] = df['lyrics'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb39c6d3-bb42-4291-86b2-2cb0467fecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import regular expression\n",
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "df['text_tokenized'] = df['lyrics_clean'].apply(lambda x: tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "460590b8-49fc-485d-9860-cb5734db3067",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_lyrics'] = df['text_tokenized'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ed47d2f-0afe-4cff-8283-99e26ac7dc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30443 entries, 0 to 3046\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Unnamed: 0         30443 non-null  int64  \n",
      " 1   song_id            30443 non-null  object \n",
      " 2   chart_position     30443 non-null  int64  \n",
      " 3   chart_date         30443 non-null  object \n",
      " 4   song               30443 non-null  object \n",
      " 5   performer          30443 non-null  object \n",
      " 6   time_on_chart      30443 non-null  int64  \n",
      " 7   consecutive_weeks  27315 non-null  float64\n",
      " 8   worst_position     30443 non-null  int64  \n",
      " 9   chart_debut        30443 non-null  object \n",
      " 10  lyrics             30443 non-null  object \n",
      " 11  lyrics_clean       30443 non-null  object \n",
      " 12  text_tokenized     30443 non-null  object \n",
      " 13  num_lyrics         30443 non-null  int64  \n",
      "dtypes: float64(1), int64(5), object(8)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b8a92b2-2ed7-4a8f-85f1-a6a3ca53e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Unnamed: 0\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f702999-745a-46d5-9759-f430beb04472",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3e129ae-1d61-4c55-ad39-71489797f6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"index\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1490dc02-7483-40ab-b7a6-e2850f9bcaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f968d55bbb0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAd2ElEQVR4nO3df1RUdeL/8dcMI4ohMDOApKulAWezLFixlFSs2Nqy9nhcs3XXbSXbMmlN2Tq5ud86HfNkW4hZkK56+nl2T+0m7LZ7znYOUVDRD9SD/bBSBHfloCLMgLCiw4/7+cNvczSHBGLmDfJ8/MW8Z+7c1wz44s3be+faLMuyBAAIObvpAAAwVFHAAGAIBQwAhlDAAGAIBQwAhjhMBwiVurq6Xj3e5XLJ4/EEKU3vkKV7AykPWQIjizRmzJiA48yAu2G3D5y3hizdG0h5yBIYWbo3sNIAwBBCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIY5Q7KShoUH5+flqamqSzWZTZmambr75ZrW2tiovL09Hjx5VXFycVq5cqcjISElSYWGhSkpKZLfblZWVpZSUFElSdXW18vPz5fP5lJqaqqysLNlstlC8DADoVyGZAYeFhelXv/qV8vLytHbtWr311luqra1VUVGRJk+erI0bN2ry5MkqKiqSJNXW1qq8vFzr16/X6tWrtW3bNnV1dUmStmzZonvuuUcbN27U4cOHVVlZGYqXAAD9LiQF7HQ6NXHiRElSRESExo4dK4/Ho4qKCmVkZEiSMjIyVFFRIUmqqKhQenq6hg0bpvj4eCUkJKiqqkper1dtbW1KTk6WzWbTrFmz/NsAwGATkiWI09XX16umpkaJiYlqbm6W0+mUdKqkjx07JknyeDxKSkryb+NyueTxeBQWFia32+0fd7vd8ng8AfdTXFys4uJiSdK6desUGxvbq5wOh6PX2wQLWbo3kPKQJTCydC+kBXzixAnl5uZq8eLFGjlyZLePsyyrV+OBZGZmKjMz03+7oaGh50ElxcbG9nqbYCFL9wZSHrIERhZpzJgxAcdDdhRER0eHcnNzNXPmTF199dWSpOjoaHm9XkmS1+tVVFSUpFMz28bGRv+2Ho9HLpfrrPHGxka5XK5QvQQA6FchKWDLsrRp0yaNHTtWt9xyi388LS1NpaWlkqTS0lJNnTrVP15eXq729nbV19fr0KFDSkxMlNPpVEREhPbu3SvLslRWVqa0tLRQvAQA6HchWYL4+uuvVVZWpvHjx+vBBx+UJC1cuFBz585VXl6eSkpKFBsbq5ycHEnSuHHjNH36dOXk5Mhut2vJkiWy20/9rrjrrrtUUFAgn8+nlJQUpaamhuIlAEC/s1m9WVgdxOrq6nr1eNatAhtIWaSBlYcsgZFlAKwBAwDORAEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAYQgEDgCEUMAAY4gjFTgoKCrRr1y5FR0crNzdXkvT666/r7bffVlRUlCRp4cKF+tGPfiRJKiwsVElJiex2u7KyspSSkiJJqq6uVn5+vnw+n1JTU5WVlSWbzRaKlwAA/S4kBTx79mz95Cc/UX5+/hnjc+bM0U9/+tMzxmpra1VeXq7169fL6/VqzZo1euaZZ2S327Vlyxbdc889SkpK0hNPPKHKykqlpqaG4iUAQL8LyRLEpEmTFBkZ2aPHVlRUKD09XcOGDVN8fLwSEhJUVVUlr9ertrY2JScny2azadasWaqoqAhycgAInpDMgLvz1ltvqaysTBMnTtQdd9yhyMhIeTweJSUl+R/jcrnk8XgUFhYmt9vtH3e73fJ4PN0+d3FxsYqLiyVJ69atU2xsbK+yORyOXm8TLGTp3kDKQ5bAyNI9YwV8ww03aP78+ZKk1157TS+//LKWLVsmy7ICPr678e5kZmYqMzPTf7uhoaFX28fGxvZ6m2AhS/cGUh6yBEYWacyYMQHHjR0FERMTI7vdLrvdruuvv1779++XdGpm29jY6H+cx+ORy+U6a7yxsVEulyvkuQGgvxgrYK/X6//6k08+0bhx4yRJaWlpKi8vV3t7u+rr63Xo0CElJibK6XQqIiJCe/fulWVZKisrU1pamqn4APC9hWQJYsOGDdqzZ49aWlq0dOlSLViwQF988YUOHDggm82muLg43X333ZKkcePGafr06crJyZHdbteSJUtkt5/6PXHXXXepoKBAPp9PKSkpHAEBYFCzWb1dXB2k6urqevV41q0CG0hZpIGVhyyBkWUArgEDwFBHAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIRQwABhCAQOAIT0u4A8//DDg+EcffdRvYQBgKOlxAW/atCng+ObNm/stDAAMJef8POAjR45Ikrq6ulRfX3/GpYGOHDmi8PDw4KUDgPPYOQt4+fLl/q9/+9vfnnFfTEyMbrvttv5PBQBDwDkL+LXXXpMkPfroo3rssceCHggAhooerwFTvgDQv3p8Tbj6+nr95S9/0YEDB3TixIkz7nv++ef7PRgAnO96XMDPPPOMRo8erTvuuEPDhw8PZiYAGBJ6XMC1tbVas2aN/wrFAIDvp8dteumll+rAgQNBjAIAQ0uPZ8BxcXFau3atrrrqKsXExJxx3+23397fuQDgvNfjAj558qSmTJmizs5ONTY2BjMTAAwJPS7gZcuWBTMHAAw5PS7gb05JDmT06NH9EgYAhpIeF/DppyR/2zdnywEAeq7HBfztkm1qatJf//pXXXrppf0eCgCGgj4f1BsTE6PFixfrz3/+c3/mAYAh43udVVFXV6eTJ0/2VxYAGFJ6vATxyCOPyGaz+W+fPHlSBw8e1Pz584MSDADOdz0u4Ouuu+6M2yNGjNBFF12kCy+8sN9DAcBQ0OMCnj17dhBjAMDQ0+MC7ujo0Pbt21VWViav1yun06lZs2Zp3rx5cjh6/DQAgP+vx8356quvav/+/frNb36juLg4HT16VG+88YaOHz+uxYsXBzEiAJyfelzAH330kZ566imNGjVKkjRmzBhNmDBBDz74IAUMAH3Q48PQTr8aMgDg++vxDHj69Ol68sknNX/+fMXGxqqhoUFvvPGGpk2bFsx8AHDe6nEBL1q0SG+88Ya2bdsmr9crl8ula665Rj/72c+CmQ8AzlvnLOCvvvpKO3bs0KJFi3T77bef8eHrr776qqqrq5WcnBzUkABwPjrnGnBhYaEmTZoU8L7LL79c27dv7/dQADAUnLOADxw4oJSUlID3TZ48WTU1Nf2dCQCGhHMWcFtbmzo6OgLe19nZqba2tn4PBQBDwTkLeOzYsdq9e3fA+3bv3q2xY8f2eygAGArOWcBz5szRn/70J3388cfq6uqSJHV1denjjz/Wli1bNGfOnKCHBIDz0TmPgpgxY4aampqUn5+v9vZ2RUVF6dixYwoPD9dtt92mGTNmhCInAJx3enQc8C233KLrrrtOe/fuVWtrqyIjI5WcnKyRI0cGOx8AnLd6fCLGyJEjuz0aAgDQe9/rkkQAgL6jgAHAEAoYAAyhgAHAEAoYAAwJycXcCgoKtGvXLkVHRys3N1eS1Nraqry8PB09elRxcXFauXKlIiMjJZ36AKCSkhLZ7XZlZWX5j76orq5Wfn6+fD6fUlNTlZWVJZvNFoqXAAD9LiQz4NmzZ+vhhx8+Y6yoqEiTJ0/Wxo0bNXnyZBUVFUmSamtrVV5ervXr12v16tXatm2b/wy8LVu26J577tHGjRt1+PBhVVZWhiI+AARFSAp40qRJ/tntNyoqKpSRkSFJysjIUEVFhX88PT1dw4YNU3x8vBISElRVVSWv16u2tjYlJyfLZrNp1qxZ/m0AYDAydj355uZmOZ1OSZLT6dSxY8ckSR6PR0lJSf7HuVwueTwehYWFye12+8fdbrc8Hk+3z19cXKzi4mJJ0rp16xQbG9urfA6Ho9fbBAtZujeQ8pAlMLJ0z1gBd6e7i3/29qKgmZmZyszM9N9uaGjo1fbfXPduICBL9wZSHrIERpZTV5EPxNhRENHR0fJ6vZIkr9erqKgoSadmto2Njf7HeTweuVyus8YbGxvlcrlCGxoA+pGxAk5LS1NpaakkqbS0VFOnTvWPl5eXq729XfX19Tp06JASExPldDoVERGhvXv3yrIslZWVKS0tzVR8APjeQrIEsWHDBu3Zs0ctLS1aunSpFixYoLlz5yovL08lJSWKjY1VTk6OJGncuHGaPn26cnJyZLfbtWTJEtntp35P3HXXXSooKJDP51NKSopSU1NDER8AgsJm9XZxdZCqq6vr1eNZtwpsIGWRBlYesgRGlgG4BgwAQx0FDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgF3A3P/7vPdAQA5zkKGAAMoYABwBAKGAAMoYABwBAKGAAMoYABwBAKGAAMoYABwBAKGAAMoYABwBAKGAAMoYABwBAKGAAMoYABwBAKGAAMoYABwBAKGAAMoYABwBAKGAAMoYABwBAKGAAMoYABwBAKGAAMoYABwBAKGAAMoYABwBAKGAAMoYABwBAKGAAMoYABwBAKGAAMoYABwBAKGAAMcZgOkJ2drREjRshutyssLEzr1q1Ta2ur8vLydPToUcXFxWnlypWKjIyUJBUWFqqkpER2u11ZWVlKSUkx+wIAoI+MF7AkPfroo4qKivLfLioq0uTJkzV37lwVFRWpqKhIixYtUm1trcrLy7V+/Xp5vV6tWbNGzzzzjOx2JvIABp8B2VwVFRXKyMiQJGVkZKiiosI/np6ermHDhik+Pl4JCQmqqqoyGRUA+mxAzIDXrl0rSfrxj3+szMxMNTc3y+l0SpKcTqeOHTsmSfJ4PEpKSvJv53K55PF4Aj5ncXGxiouLJUnr1q1TbGxsrzJ5bbZebxMsDoeDLN0YSHnIEhhZume8gNesWSOXy6Xm5mY9/vjjGjNmTLePtSyrx8+bmZmpzMxM/+2GhoZe5bJbVq+3CZbY2FiydGMg5SFLYGRRt71mfAnC5XJJkqKjozV16lRVVVUpOjpaXq9XkuT1ev3rw263W42Njf5tPR6Pf3sAGGyMFvCJEyfU1tbm//rTTz/V+PHjlZaWptLSUklSaWmppk6dKklKS0tTeXm52tvbVV9fr0OHDikxMdFYfgD4PowuQTQ3N+vpp5+WJHV2dmrGjBlKSUnRJZdcory8PJWUlCg2NlY5OTmSpHHjxmn69OnKycmR3W7XkiVLOAICwKBltIBHjx6tp5566qzxUaNG6ZFHHgm4zbx58zRv3rxgRwOAoGP6CACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMAAYAgFDACGUMDfofPp1aYjADiPUcAAYAgFDACGUMAAYIjDdIC+qKys1AsvvKCuri5df/31mjt3rulIANBrg24G3NXVpW3btunhhx9WXl6ePvjgA9XW1pqOBQC9NugKuKqqSgkJCRo9erQcDofS09NVUVERtP19cyRE59OrA37d2+fp6f0cgQGc/2yWZVmmQ/TGRx99pMrKSi1dulSSVFZWpn379mnJkiVnPK64uFjFxcWSpHXr1oU8JwCcy6CbAQf6fWGz2c4ay8zM1Lp16/pcvqtWrerTdsFAlu4NpDxkCYws3Rt0Bex2u9XY2Oi/3djYKKfTaTARAPTNoCvgSy65RIcOHVJ9fb06OjpUXl6utLQ007EAoNcG3WFoYWFhuvPOO7V27Vp1dXXp2muv1bhx4/p9P5mZmf3+nH1Flu4NpDxkCYws3Rt0/wkHAOeLQbcEAQDnCwoYAAwZdGvAwRas05wbGhqUn5+vpqYm2Ww2ZWZm6uabb1Zra6vy8vJ09OhRxcXFaeXKlYqMjJQkFRYWqqSkRHa7XVlZWUpJSZEkVVdXKz8/Xz6fT6mpqcrKypLNZlN7e7uee+45VVdXa9SoUVqxYoXi4+O7zdTV1aVVq1bJ5XJp1apVxrL873//06ZNm3Tw4EHZbDbde++9GjNmjJEs//znP1VSUiKbzaZx48Zp2bJl8vl8IctSUFCgXbt2KTo6Wrm5uZIUsu/Lu+++q+3bt0uS5s2bpz179pyV5ZVXXtHOnTvlcDg0evRoLVu2TBdccIGRLN/4xz/+oVdffVVbt25VVFRU0LPMnj074M9On1jw6+zstO677z7r8OHDVnt7u/XAAw9YBw8e7Jfn9ng81v79+y3Lsqzjx49by5cvtw4ePGi98sorVmFhoWVZllVYWGi98sorlmVZ1sGDB60HHnjA8vl81pEjR6z77rvP6uzstCzLslatWmV9/fXXVldXl7V27Vpr165dlmVZ1r///W9r8+bNlmVZ1vvvv2+tX7/+OzO9+eab1oYNG6wnnnjCsizLWJZnn33WKi4utizLstrb263W1lYjWRobG61ly5ZZJ0+etCzLsnJzc6133nknpFm++OILa//+/VZOTo5/LBT7b2lpsbKzs62Wlhb/1zt27DgrS2VlpdXR0eHPZTKLZVnW0aNHrccff9y69957rebm5pBkaWlpCfjz0xcsQZwmmKc5O51OTZw4UZIUERGhsWPHyuPxqKKiQhkZGZKkjIwM//4qKiqUnp6uYcOGKT4+XgkJCaqqqpLX61VbW5uSk5Nls9k0a9Ys/zY7duzw/3aeNm2aPv/884Anrkinjp/etWuXrr/+ev+YiSzHjx/Xl19+qeuuu06S5HA4dMEFFxh7X7q6uuTz+dTZ2Smfzyen0xnSLJMmTfLPbkP5famsrNQVV1yhyMhIRUZG6oorrlBbW9tZWa688kqFhYVJkpKTk+XxeIxlkaSXXnpJv/zlL884GSvYWSorKwP+7PQFSxCn8Xg8crvd/ttut1v79u3r9/3U19erpqZGiYmJam5u9p9I4nQ6dezYMX+WpKQk/zYul0sej0dhYWFnZfzmH8Hp+cPCwjRy5Ei1tLT4/yw73YsvvqhFixapra3NP2YiS319vaKiolRQUKD//Oc/mjhxohYvXmwki8vl0q233qp7771X4eHhuvLKK3XllVca+x6F8vvy7Z/9b57ru5SUlCg9Pd1Ylh07dsjlcuniiy8+Y9z0+9IbzIBPE2hWFOg05+/jxIkTys3N1eLFizVy5MheZfmu8e7uC5R/586dio6O9s/IzyWYWTo7O1VTU6MbbrhBf/zjHzV8+HAVFRUZydLa2qqKigrl5+dr8+bNOnHihMrKyoxk6Ylg7/+7cm3fvl1hYWGaOXOmkSwnT57U9u3bdfvtt/d4n6F4X3qLAj5NsE9z7ujoUG5urmbOnKmrr75akhQdHS2v1ytJ8nq9/pnQt7N4PB65XK6AGV0u11nbdHZ26vjx4wH/bPv666+1Y8cOZWdna8OGDfr888+1ceNGI1ncbrfcbrd/xjJt2jTV1NQYyfLZZ58pPj5eUVFRcjgcuvrqq7V3714jWU4Xiv27XK6znqu7n/13331XO3fu1PLly/1lFOosR44cUX19vR588EFlZ2ersbFRDz30kJqamoy9L31BAZ8mmKc5W5alTZs2aezYsbrlllv842lpaSotLZUklZaWaurUqf7x8vJytbe3q76+XocOHVJiYqKcTqciIiK0d+9eWZalsrIyf8YpU6bo3XfflXTqU+Muu+yygL+tf/GLX2jTpk3Kz8/XihUrdPnll2v58uVGssTExMjtdquurk7SqRL8wQ9+YCRLbGys9u3bp5MnT8qyLH322WcaO3askSynC8X+U1JStHv3brW2tqq1tVW7d+/2HzlwusrKSv3973/XQw89pOHDh5+RMZRZxo8fr61btyo/P1/5+flyu9168sknFRMTY+R96SvOhPuWXbt26aWXXvKf5jxv3rx+ed6vvvpKjzzyiMaPH+//B7dw4UIlJSUpLy9PDQ0Nio2NVU5Ojn9GtH37dr3zzjuy2+1avHixUlNTJUn79+9XQUGBfD6fUlJSdOedd8pms8nn8+m5555TTU2NIiMjtWLFCo0ePfo7c33xxRd68803tWrVKrW0tBjJcuDAAW3atEkdHR2Kj4/XsmXLZFmWkSyvv/66ysvLFRYWposvvlhLly7ViRMnQpZlw4YN2rNnj1paWhQdHa0FCxZo6tSpIdl/SUmJCgsLJZ063Gr37t1nZSksLFRHR4d//0lJSbr77ruNZPnmP24lKTs7W0888YT/r4NgZrn22msD/uz0BQUMAIawBAEAhlDAAGAIBQwAhlDAAGAIBQwAhlDAQA9kZ2fr008/7dO27733nh5//PF+ToTzAZ8FAQTZzJkz/afsAqdjBgwEUWdnp+kIGMCYAWNQyM7O1o033qiysjIdPXpUKSkpys7OVnl5ud5++22tWbPG/9gFCxZo48aNSkhIUH5+voYPH676+np9+eWXuvjii/W73/1ORUVFKi0tVXR0tO6//35NmDChRzmampp033336fnnn9eoUaMknfqQ77Vr12rz5s16//339fbbb+uSSy5RaWmpbrzxRiUkJJyR8eDBg3rxxRdVXV0th8Ohm266SfPmzVNVVZW2bt2qQ4cOKTw8XDNmzNCvf/3r/n8zMWAwA8ag8eGHH+rhhx9Wfn6+/vvf//rP3e/Jdj//+c+1bds2ORwOrV69WhMmTNC2bds0bdo0vfzyyz3OEBMTo8suu0wffvihf6ysrEzXXHONHI5T85l9+/Zp9OjR2rp161mnsre1tWnNmjVKSUnR5s2btXHjRk2ePFmS9MILL+jmm2/WSy+9pGeffVbTp0/vcS4MThQwBo2bbrpJLpdLkZGRmjJlig4cONCj7aZOnaqJEycqPDxcV111lcLDw5WRkSG73a709HTV1NT0KkdGRobee+89Sac+wP2DDz7QrFmz/Pc7nU7ddNNNCgsLU3h4+Bnb7ty5UzExMbr11lsVHh6uiIgI/yfBORwOHT58WMeOHdOIESOUnJzcq1wYfChgDBoxMTH+r8PDw3XixIk+bRcdHd2n5/lGWlqaamtrdeTIEX366acaOXKkEhMT/ffHxsZ2u21jY2O3HwS0dOlS1dXVaeXKlfr973+vnTt39ioXBh/WgDGoDR8+XD6fz3+7qakp6PsMDw/X9OnT9d5776muru6M2e+5uN1uffDBBwHvu/DCC7VixQp1dXXpk08+0fr167Vt2zaNGDGiv6JjgGEGjEHtoosu0sGDB3XgwAH5fD69/vrrIdnvrFmzVFpaqh07dvTqELMpU6aoqalJ//rXv9Te3q62tjb/Za/Kysp07Ngx2e12/9VS7Hb+iZ7PmAFjUBszZozmz5+vNWvWKDw8XAsXLlRxcXHQ9/vDH/5QNptNEyZM6PYS94FEREToD3/4g1588UX97W9/k8Ph0Jw5c5SUlKTKykq9/PLLOnnypOLi4nT//feftYaM8wufBwz00WOPPaYZM2accWVpoDf4+wbog6qqKtXU1PivCgz0BUsQgKSGhgatXLky4H15eXlnHNnw3HPPqaKiQllZWYqIiAhVRJyHWIIAAENYggAAQyhgADCEAgYAQyhgADCEAgYAQ/4P8aEP0ABhJ44AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize distribution of num of lyrics\n",
    "\n",
    "sns.displot(data=df, x=\"num_lyrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7659ecbc-6408-4cf0-a4bc-9550957819d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2232"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['num_lyrics'] > 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b34be98a-f79d-4f3b-94c7-8bb66751ff08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4904"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['num_lyrics'] > 513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25d5a694-0737-4e87-b999-f2b98c1aec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['num_lyrics'] > 2000].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68cce880-eebe-4e1d-b75f-fe4de6ff35f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2312"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['num_lyrics'] == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4edabf36-94b5-4a3d-a5b9-c8764efdc5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f946e55dee0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(data=df, x=\"num_lyrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c2c8c79-adf3-4b88-9c67-97b972d99bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2312"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['lyrics'] == \"not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22a65d1f-cd37-495e-987b-b062711ac8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['lyrics'] == 'not found'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "841e1a7f-8509-4e96-907d-3758469cc338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26051 entries, 0 to 30442\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   song_id            26051 non-null  object \n",
      " 1   chart_position     26051 non-null  int64  \n",
      " 2   chart_date         26051 non-null  object \n",
      " 3   song               26051 non-null  object \n",
      " 4   performer          26051 non-null  object \n",
      " 5   time_on_chart      26051 non-null  int64  \n",
      " 6   consecutive_weeks  23300 non-null  float64\n",
      " 7   worst_position     26051 non-null  int64  \n",
      " 8   chart_debut        26051 non-null  object \n",
      " 9   lyrics             26051 non-null  object \n",
      " 10  lyrics_clean       26051 non-null  object \n",
      " 11  text_tokenized     26051 non-null  object \n",
      " 12  num_lyrics         26051 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(8)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81b6cce1-555b-41f2-897a-8e415d7dac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc64ce38-e489-4824-a79e-33351965ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ae8fd73-4b08-4d83-985f-b49e4064878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "string.punctuation\n",
    "\n",
    "def remove_punct(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca67e159-1cbe-43c0-95be-e61f4ebad7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lyrics'] = df['lyrics'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "04135485-ddb0-4ecd-990a-761bd9fa9c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['song_id'] = df['song_id'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "96a391ba-e5cd-43b2-b445-3d584b6641ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ast\n",
    "#test['lyrics'] = test[\"lyrics\"].apply(ast.literal_eval).str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be9afc03-341b-46d5-8d1b-7cb26ace1268",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26051/26051 [02:18<00:00, 187.89it/s]\n"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    text = row['lyrics']\n",
    "    myid = row['song_id']\n",
    "    res[myid] = sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8716355-3904-41c4-acba-36c8795371a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result = pd.DataFrame(res).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0da0832-b0bd-44a4-b0e7-2cd1e3b86de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\"B\" GirlsYoung And Restless</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.9706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"Joy\" Pt. IIsaac Hayes</th>\n",
       "      <td>0.113</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.2103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#1 Dee JayGoody Goody</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.8957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#1Nelly</th>\n",
       "      <td>0.114</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#9 DreamJohn Lennon</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.9124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               neg    neu    pos  compound\n",
       "\"B\" GirlsYoung And Restless  0.017  0.918  0.065    0.9706\n",
       "\"Joy\" Pt. IIsaac Hayes       0.113  0.776  0.110   -0.2103\n",
       "#1 Dee JayGoody Goody        0.024  0.929  0.048    0.8957\n",
       "#1Nelly                      0.114  0.759  0.127   -0.1135\n",
       "#9 DreamJohn Lennon          0.012  0.893  0.095    0.9124"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0be3e58d-cb4e-4de7-b37d-800a6fb02eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result = Result.reset_index().rename(columns={'index': 'song_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10802e24-11e1-42ab-b881-d8f5f06270be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = Result.merge(df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbf299c-db14-414a-90e5-8fad3c6f7771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "\n",
    "filepath = Path('./data/nltk_lyric_sentiment.csv')  \n",
    "sentiment_df.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3db77d7-6972-4365-83a0-6286f805d42c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5ea93be-c81e-4230-953d-bf0b54fede28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/nltk_lyric_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096a5cfd-d759-4f2b-bd75-ea85083f7e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79207421-d420-4f8e-bd88-0e138a477d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Unnamed: 0\", 'neg', 'neu', 'pos', 'compound', 'lyrics_clean', 'text_tokenized'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "00f85d8f-a262-4818-aa2f-3f47a360785c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4904"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['num_lyrics'] > 513)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0bb45fed-356a-43d9-a39f-0ef62c189182",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['num_lyrics'] > 500].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a4bbf76-7ac9-4484-be96-3e2c68412004",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"i'll never be your beast of burden. My back is broke, my feet a hurtin' all i want is for you to make love to me\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bb777ca-4673-49a1-adfe-f95a9bd30293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0166123e-a321-4f55-babc-494cb8950a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9be6efb7-89fc-46dd-9907-1d5ec31cf730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.183, 'neu': 0.641, 'pos': 0.176, 'compound': -0.0516}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "055c1d73-1021-404f-bcb8-2014cf330973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc3fbee3-9f79-44a5-b6b8-1c0137762b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e44bacd7-74a4-4c82-88ab-97803c2cddab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['num_lyrics'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7f97b2-e914-403d-9381-1b28dccf9a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8a8789d7-d561-4262-986a-0c2cd7731074",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lyric_char_len'] = pd.Series(dtype='int')\n",
    "\n",
    "df['lyrics_char_len'] = [len(x) for x in df['lyrics']] \n",
    "\n",
    "#for i, row in df.iterrows():\n",
    "    \n",
    " #   text = row['lyrics']\n",
    "  #  row['lyric_char_len'] = len(text)\n",
    "   # print(len(text))\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "76782e17-0fcd-4471-93cd-d61cdc36eadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8983"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lyrics_char_len'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "09941fc9-5f88-4e99-ba20-aff6000b6f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24823"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lyrics_char_len'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c2782b0b-9df4-445c-8d1c-a8b82e455985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "60c90384-59eb-419e-8979-47a00b9578b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>chart_position</th>\n",
       "      <th>chart_date</th>\n",
       "      <th>song</th>\n",
       "      <th>performer</th>\n",
       "      <th>time_on_chart</th>\n",
       "      <th>consecutive_weeks</th>\n",
       "      <th>worst_position</th>\n",
       "      <th>chart_debut</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>num_lyrics</th>\n",
       "      <th>lyric_char_len</th>\n",
       "      <th>lyrics_char_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#9 DreamJohn Lennon</td>\n",
       "      <td>68</td>\n",
       "      <td>1975-03-08</td>\n",
       "      <td>#9 Dream</td>\n",
       "      <td>John Lennon</td>\n",
       "      <td>12</td>\n",
       "      <td>11.0</td>\n",
       "      <td>68</td>\n",
       "      <td>1974-12-21</td>\n",
       "      <td>9 Dream LyricsVerse 1\\nSo long ago\\nWas it in ...</td>\n",
       "      <td>206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#BeautifulMariah Carey Featuring Miguel</td>\n",
       "      <td>95</td>\n",
       "      <td>2013-09-07</td>\n",
       "      <td>#Beautiful</td>\n",
       "      <td>Mariah Carey Featuring Miguel</td>\n",
       "      <td>16</td>\n",
       "      <td>15.0</td>\n",
       "      <td>95</td>\n",
       "      <td>2013-05-25</td>\n",
       "      <td>Beautiful LyricsIntro Mariah Carey\\nAh ah you’...</td>\n",
       "      <td>292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#SELFIEThe Chainsmokers</td>\n",
       "      <td>95</td>\n",
       "      <td>2014-05-24</td>\n",
       "      <td>#SELFIE</td>\n",
       "      <td>The Chainsmokers</td>\n",
       "      <td>11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>95</td>\n",
       "      <td>2014-03-15</td>\n",
       "      <td>TranslationsPortuguêsEnglishSELFIE LyricsVerse...</td>\n",
       "      <td>365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   song_id  chart_position  chart_date  \\\n",
       "4                      #9 DreamJohn Lennon              68  1975-03-08   \n",
       "5  #BeautifulMariah Carey Featuring Miguel              95  2013-09-07   \n",
       "6                  #SELFIEThe Chainsmokers              95  2014-05-24   \n",
       "\n",
       "         song                      performer  time_on_chart  \\\n",
       "4    #9 Dream                    John Lennon             12   \n",
       "5  #Beautiful  Mariah Carey Featuring Miguel             16   \n",
       "6     #SELFIE               The Chainsmokers             11   \n",
       "\n",
       "   consecutive_weeks  worst_position chart_debut  \\\n",
       "4               11.0              68  1974-12-21   \n",
       "5               15.0              95  2013-05-25   \n",
       "6               10.0              95  2014-03-15   \n",
       "\n",
       "                                              lyrics  num_lyrics  \\\n",
       "4  9 Dream LyricsVerse 1\\nSo long ago\\nWas it in ...         206   \n",
       "5  Beautiful LyricsIntro Mariah Carey\\nAh ah you’...         292   \n",
       "6  TranslationsPortuguêsEnglishSELFIE LyricsVerse...         365   \n",
       "\n",
       "   lyric_char_len  lyrics_char_len  \n",
       "4             NaN             1145  \n",
       "5             NaN             1539  \n",
       "6             NaN             1769  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a2c65520-28b9-492e-8e04-08898074db7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20866 entries, 4 to 26050\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   song_id            20866 non-null  object \n",
      " 1   chart_position     20866 non-null  int64  \n",
      " 2   chart_date         20866 non-null  object \n",
      " 3   song               20866 non-null  object \n",
      " 4   performer          20866 non-null  object \n",
      " 5   time_on_chart      20866 non-null  int64  \n",
      " 6   consecutive_weeks  19105 non-null  float64\n",
      " 7   worst_position     20866 non-null  int64  \n",
      " 8   chart_debut        20866 non-null  object \n",
      " 9   lyrics             20866 non-null  object \n",
      " 10  num_lyrics         20866 non-null  int64  \n",
      " 11  lyric_char_len     0 non-null      float64\n",
      " 12  lyrics_char_len    20866 non-null  int64  \n",
      "dtypes: float64(2), int64(5), object(6)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d99ac67-b735-4362-8bee-f5524e2a6cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bc84bfbd-345e-43ab-aa0b-cba8b62c53bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2131\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2140\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [139]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m var \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlyrics\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(var)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "var = df['lyrics'][0]\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b09449c1-d563-4594-a06d-9d885b8dbd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roberta_neg': 0.63558716, 'roberta_neu': 0.29613292, 'roberta_pos': 0.06828004}\n"
     ]
    }
   ],
   "source": [
    "# Runfor Roberta Model\n",
    "\n",
    "encoded_text = tokenizer(example, return_tensors='tf')\n",
    "\n",
    "output = model(**encoded_text)\n",
    "scores = output[0][0].numpy()\n",
    "scores = softmax(scores)\n",
    "scores_dict = {\n",
    "    'roberta_neg' : scores[0],\n",
    "    'roberta_neu' : scores[1],\n",
    "    'roberta_pos' : scores[2]\n",
    "    }\n",
    "print(scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a496bfbf-ab6a-458d-9ad9-8187c57afb0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 7309), dtype=int32, numpy=array([[    0, 19163, 48111, ..., 42578,   196,     2]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 7309), dtype=int32, numpy=array([[1, 1, 1, ..., 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(example2, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ca511550-e09c-47ae-99c9-a3affc3f30ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8983"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "44d25da1-74d8-4c3e-a1ee-42b03dd08a50",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roberta_neg': 0.18051265, 'roberta_neu': 0.53359777, 'roberta_pos': 0.28588954}\n"
     ]
    }
   ],
   "source": [
    "encoded_text = tokenizer(example2, return_tensors='tf')\n",
    "\n",
    "output = model(**encoded_text)\n",
    "scores = output[0][0].numpy()\n",
    "scores = softmax(scores)\n",
    "scores_dict = {\n",
    "    'roberta_neg' : scores[0],\n",
    "    'roberta_neu' : scores[1],\n",
    "    'roberta_pos' : scores[2]\n",
    "    }\n",
    "print(scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "923ee926-82f2-4365-9d0c-d89d85c7517f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63558716, 0.29613292, 0.06828004], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f58cac91-55a8-471a-9d74-a6ef56d4f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_scores_roberta(example):\n",
    "    encoded_text = tokenizer(example, return_tensors='tf')\n",
    "\n",
    "    \n",
    "   # def function(**encoded_text):\n",
    "    #    for i in encoded_text:\n",
    "     #       print(i, encoded_text[i])\n",
    "    \n",
    "    #function(**encoded_text)\n",
    "\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "        'roberta_neg' : scores[0],\n",
    "        'roberta_neu' : scores[1],\n",
    "        'roberta_pos' : scores[2]\n",
    "    }\n",
    "    \n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1e3c43f9-f8ef-4319-a99c-03ccfaff6591",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TranslationsPortuguêsthatPOWER LyricsInstrumental Intro\n",
      "\n",
      "PreChorus Justin Bieber\n",
      "And oh Im alive Im alive Im alive\n",
      "And oh I can fly I can fly I can fly\n",
      "And oh Im alive Im alive Im alive\n",
      "And Im lovin every second minute hour\n",
      "Bigger better stronger power\n",
      "\n",
      "Chorus william william  Justin Bieber\n",
      "I got that power\n",
      "I got that power\n",
      "I got that power\n",
      "Power power power\n",
      "\n",
      "Verse 1 william\n",
      "They call me WillA stay so cool Im chilly\n",
      "I done made that milli on my way to that billi\n",
      "Used to have a piggy bank but now I got that bigger bank\n",
      "Whowho cares what the haters think\n",
      "They hatin on me cause Im doin what they cant\n",
      "I stay on that hustle I flex that mental muscle\n",
      "Hate to bust your bubble Im on that other level\n",
      "\n",
      "Refrain william\n",
      "Ima take it higher and high high and higher\n",
      "I stay in fly attire\n",
      "Keep burnin like that fire\n",
      "You might also likePreChorus Justin Bieber\n",
      "And oh Im alive Im alive Im alive\n",
      "And oh I can fly I can fly I can fly\n",
      "And oh Im alive Im alive Im alive\n",
      "And Im lovin every second minute hour\n",
      "Bigger better stronger power\n",
      "\n",
      "Chorus william william  Justin Bieber\n",
      "I got that power\n",
      "I got that power\n",
      "I got that power\n",
      "Power power power\n",
      "\n",
      "Verse 2 william\n",
      "Yyyyes yall feelin funky fresh yall\n",
      "Work to be the best yall work good under pressure\n",
      "Been through all that stress yall get this off my chest yall\n",
      "Made it out them projects with this project thats progress yall\n",
      "I did it for my momma I told her when I was younger\n",
      "That Ima be that number one yup Ill be that number one\n",
      "\n",
      "Refrain william\n",
      "I take it higher and high high and higher\n",
      "I stay and buy attire\n",
      "Keep burnin like that fire\n",
      "Bridge william\n",
      "Whatever doesnt kill ya only makes you stronger\n",
      "So Ima get stronger\n",
      "Comin like a batterram batterram\n",
      "Im knockinknockin down the door again door again\n",
      "Comincomin like a batterram batterram\n",
      "Im knockinknockin down the door again door again\n",
      "\n",
      "PreChorus Justin Bieber\n",
      "And oh Im alive Im alive Im alive\n",
      "And oh I can fly I can fly I can fly\n",
      "And oh Im alive Im alive Im alive\n",
      "And Im lovin every second minute hour\n",
      "Bigger better stronger power\n",
      "\n",
      "Chorus william william  Justin Bieber\n",
      "I got that power\n",
      "I got that power\n",
      "I got that power\n",
      "Power power power\n",
      "\n",
      "Outro Justin Bieber\n",
      "And Im lovin every second minute hour\n",
      "Bigger better stronger power\n",
      "And Im lovin every second minute hour\n",
      "Bigger better stronger power27Embed\n",
      "2294\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'embeddings' (type TFRobertaEmbeddings).\n\n{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0,512] = 514 is not in [0, 514) [Op:ResourceGather]\n\nCall arguments received by layer 'embeddings' (type TFRobertaEmbeddings):\n  • input_ids=tf.Tensor(shape=(1, 613), dtype=int32)\n  • position_ids=None\n  • token_type_ids=tf.Tensor(shape=(1, 613), dtype=int32)\n  • inputs_embeds=None\n  • past_key_values_length=0\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [147]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(var)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(var))\n\u001b[0;32m----> 5\u001b[0m \u001b[43mpolarity_scores_roberta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [146]\u001b[0m, in \u001b[0;36mpolarity_scores_roberta\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m      2\u001b[0m  encoded_text \u001b[38;5;241m=\u001b[39m tokenizer(example, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# def function(**encoded_text):\u001b[39;00m\n\u001b[1;32m      6\u001b[0m  \u001b[38;5;66;03m#    for i in encoded_text:\u001b[39;00m\n\u001b[1;32m      7\u001b[0m   \u001b[38;5;66;03m#       print(i, encoded_text[i])\u001b[39;00m\n\u001b[1;32m      8\u001b[0m  \n\u001b[1;32m      9\u001b[0m  \u001b[38;5;66;03m#function(**encoded_text)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m  output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoded_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m  scores \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     13\u001b[0m  scores \u001b[38;5;241m=\u001b[39m softmax(scores)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:433\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    432\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_tf_roberta.py:1360\u001b[0m, in \u001b[0;36mTFRobertaForSequenceClassification.call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, labels, training)\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;129m@unpack_inputs\u001b[39m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;129m@add_start_docstrings_to_model_forward\u001b[39m(ROBERTA_INPUTS_DOCSTRING\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size, sequence_length\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1333\u001b[0m \u001b[38;5;129m@add_code_sample_docstrings\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1352\u001b[0m     training: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[TFSequenceClassifierOutput, Tuple[tf\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[1;32m   1354\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;124;03m    labels (`tf.Tensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;124;03m        Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;124;03m        config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;124;03m        `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1360\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m     sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1373\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output, training\u001b[38;5;241m=\u001b[39mtraining)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:433\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    432\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_tf_roberta.py:663\u001b[0m, in \u001b[0;36mTFRobertaMainLayer.call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token_type_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfill(dims\u001b[38;5;241m=\u001b[39minput_shape, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 663\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;66;03m# We create a 3D attention mask from a 2D tensor mask.\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;66;03m# Sizes are [batch_size, 1, 1, to_seq_length]\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# this attention mask is more simple than the triangular masking of causal attention\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;66;03m# used in OpenAI GPT, we just need to prepare the broadcast dimension here.\u001b[39;00m\n\u001b[1;32m    677\u001b[0m attention_mask_shape \u001b[38;5;241m=\u001b[39m shape_list(attention_mask)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_tf_roberta.py:175\u001b[0m, in \u001b[0;36mTFRobertaEmbeddings.call\u001b[0;34m(self, input_ids, position_ids, token_type_ids, inputs_embeds, past_key_values_length, training)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m         position_ids \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(\n\u001b[1;32m    172\u001b[0m             tf\u001b[38;5;241m.\u001b[39mrange(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, limit\u001b[38;5;241m=\u001b[39minput_shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    173\u001b[0m         )\n\u001b[0;32m--> 175\u001b[0m position_embeds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m token_type_embeds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mgather(params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings, indices\u001b[38;5;241m=\u001b[39mtoken_type_ids)\n\u001b[1;32m    177\u001b[0m final_embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m position_embeds \u001b[38;5;241m+\u001b[39m token_type_embeds\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'embeddings' (type TFRobertaEmbeddings).\n\n{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0,512] = 514 is not in [0, 514) [Op:ResourceGather]\n\nCall arguments received by layer 'embeddings' (type TFRobertaEmbeddings):\n  • input_ids=tf.Tensor(shape=(1, 613), dtype=int32)\n  • position_ids=None\n  • token_type_ids=tf.Tensor(shape=(1, 613), dtype=int32)\n  • inputs_embeds=None\n  • past_key_values_length=0\n  • training=False"
     ]
    }
   ],
   "source": [
    "var = df[\"lyrics\"][7]\n",
    "#var = \"x\" * 2400\n",
    "print(var)\n",
    "print(len(var))\n",
    "polarity_scores_roberta(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2139fb29-5901-41eb-9809-f2968d1f1abf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:12<00:25, 12.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:19<00:09,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:26<00:00,  8.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "--\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'embeddings' (type TFRobertaEmbeddings).\n\n{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0,512] = 514 is not in [0, 514) [Op:ResourceGather]\n\nCall arguments received by layer 'embeddings' (type TFRobertaEmbeddings):\n  • input_ids=tf.Tensor(shape=(1, 613), dtype=int32)\n  • position_ids=None\n  • token_type_ids=tf.Tensor(shape=(1, 613), dtype=int32)\n  • inputs_embeds=None\n  • past_key_values_length=0\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [142]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m roberta_result \u001b[38;5;241m=\u001b[39m \u001b[43mpolarity_scores_roberta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [141]\u001b[0m, in \u001b[0;36mpolarity_scores_roberta\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m      2\u001b[0m encoded_text \u001b[38;5;241m=\u001b[39m tokenizer(example, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#def function(**encoded_text):\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#    for i in encoded_text:\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#        print(i, encoded_text[i])\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#function(**encoded_text)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoded_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m scores \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     13\u001b[0m scores \u001b[38;5;241m=\u001b[39m softmax(scores)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:433\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    432\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_tf_roberta.py:1360\u001b[0m, in \u001b[0;36mTFRobertaForSequenceClassification.call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, labels, training)\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;129m@unpack_inputs\u001b[39m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;129m@add_start_docstrings_to_model_forward\u001b[39m(ROBERTA_INPUTS_DOCSTRING\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size, sequence_length\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1333\u001b[0m \u001b[38;5;129m@add_code_sample_docstrings\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1352\u001b[0m     training: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[TFSequenceClassifierOutput, Tuple[tf\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[1;32m   1354\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;124;03m    labels (`tf.Tensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;124;03m        Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;124;03m        config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;124;03m        `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1360\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m     sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1373\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output, training\u001b[38;5;241m=\u001b[39mtraining)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:433\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    432\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[0;32m--> 433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_tf_roberta.py:663\u001b[0m, in \u001b[0;36mTFRobertaMainLayer.call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token_type_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfill(dims\u001b[38;5;241m=\u001b[39minput_shape, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 663\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;66;03m# We create a 3D attention mask from a 2D tensor mask.\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;66;03m# Sizes are [batch_size, 1, 1, to_seq_length]\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;66;03m# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# this attention mask is more simple than the triangular masking of causal attention\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;66;03m# used in OpenAI GPT, we just need to prepare the broadcast dimension here.\u001b[39;00m\n\u001b[1;32m    677\u001b[0m attention_mask_shape \u001b[38;5;241m=\u001b[39m shape_list(attention_mask)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/roberta/modeling_tf_roberta.py:175\u001b[0m, in \u001b[0;36mTFRobertaEmbeddings.call\u001b[0;34m(self, input_ids, position_ids, token_type_ids, inputs_embeds, past_key_values_length, training)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m         position_ids \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(\n\u001b[1;32m    172\u001b[0m             tf\u001b[38;5;241m.\u001b[39mrange(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, limit\u001b[38;5;241m=\u001b[39minput_shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    173\u001b[0m         )\n\u001b[0;32m--> 175\u001b[0m position_embeds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m token_type_embeds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mgather(params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings, indices\u001b[38;5;241m=\u001b[39mtoken_type_ids)\n\u001b[1;32m    177\u001b[0m final_embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m position_embeds \u001b[38;5;241m+\u001b[39m token_type_embeds\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'embeddings' (type TFRobertaEmbeddings).\n\n{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0,512] = 514 is not in [0, 514) [Op:ResourceGather]\n\nCall arguments received by layer 'embeddings' (type TFRobertaEmbeddings):\n  • input_ids=tf.Tensor(shape=(1, 613), dtype=int32)\n  • position_ids=None\n  • token_type_ids=tf.Tensor(shape=(1, 613), dtype=int32)\n  • inputs_embeds=None\n  • past_key_values_length=0\n  • training=False"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df2)):\n",
    "    text = row['lyrics']\n",
    "    Id = row['song_id']\n",
    "    vader_result = sia.polarity_scores(text)\n",
    "    vader_result_rename = {}\n",
    "    for key, value in vader_result.items():\n",
    "        vader_result_rename[f\"vader_{key}\"] = value\n",
    "    print(i)\n",
    "    print(\"--\")\n",
    "    roberta_result = polarity_scores_roberta(text)\n",
    "    #both = {**vader_result_rename, **roberta_result}\n",
    "    #res[Id] = both\n",
    "    #if len(vader_result_rename) != len(roberta_result):\n",
    "     #   print('not similar')\n",
    "      #  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260f589-f7c4-44f7-9a28-4018725c20d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try try and catch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2b88bd6-19a7-422e-97d4-a736e54586e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result = pd.DataFrame(res).T\n",
    "#sentiment_df = Result.merge(df, right_on = 'song_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9cafe63a-7252-4be1-b6cc-f5b5c62ad1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>chart_position</th>\n",
       "      <th>chart_date</th>\n",
       "      <th>song</th>\n",
       "      <th>performer</th>\n",
       "      <th>time_on_chart</th>\n",
       "      <th>consecutive_weeks</th>\n",
       "      <th>worst_position</th>\n",
       "      <th>chart_debut</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>num_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"B\" GirlsYoung And Restless</td>\n",
       "      <td>91</td>\n",
       "      <td>1990-08-11</td>\n",
       "      <td>\"B\" Girls</td>\n",
       "      <td>Young And Restless</td>\n",
       "      <td>15</td>\n",
       "      <td>14.0</td>\n",
       "      <td>91</td>\n",
       "      <td>1990-05-05</td>\n",
       "      <td>“B” Girls LyricsIntro\\nHey Slim Come here chec...</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Joy\" Pt. IIsaac Hayes</td>\n",
       "      <td>72</td>\n",
       "      <td>1974-02-16</td>\n",
       "      <td>\"Joy\" Pt. I</td>\n",
       "      <td>Isaac Hayes</td>\n",
       "      <td>9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>72</td>\n",
       "      <td>1973-12-22</td>\n",
       "      <td>1212 Songs LyricsAAlex Turner  Stuck on the Pu...</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#1 Dee JayGoody Goody</td>\n",
       "      <td>99</td>\n",
       "      <td>1978-12-16</td>\n",
       "      <td>#1 Dee Jay</td>\n",
       "      <td>Goody Goody</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>99</td>\n",
       "      <td>1978-11-18</td>\n",
       "      <td>Lbo3d l’akhar LyricsVerse 1 Omar Cravate\\n\\nBa...</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#1Nelly</td>\n",
       "      <td>75</td>\n",
       "      <td>2002-03-02</td>\n",
       "      <td>#1</td>\n",
       "      <td>Nelly</td>\n",
       "      <td>20</td>\n",
       "      <td>19.0</td>\n",
       "      <td>75</td>\n",
       "      <td>2001-10-20</td>\n",
       "      <td>1 LyricsIntro\\nUh uh uh\\nI just gotta bring it...</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#9 DreamJohn Lennon</td>\n",
       "      <td>68</td>\n",
       "      <td>1975-03-08</td>\n",
       "      <td>#9 Dream</td>\n",
       "      <td>John Lennon</td>\n",
       "      <td>12</td>\n",
       "      <td>11.0</td>\n",
       "      <td>68</td>\n",
       "      <td>1974-12-21</td>\n",
       "      <td>9 Dream LyricsVerse 1\\nSo long ago\\nWas it in ...</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       song_id  chart_position  chart_date         song  \\\n",
       "0  \"B\" GirlsYoung And Restless              91  1990-08-11    \"B\" Girls   \n",
       "1       \"Joy\" Pt. IIsaac Hayes              72  1974-02-16  \"Joy\" Pt. I   \n",
       "2        #1 Dee JayGoody Goody              99  1978-12-16   #1 Dee Jay   \n",
       "3                      #1Nelly              75  2002-03-02           #1   \n",
       "4          #9 DreamJohn Lennon              68  1975-03-08     #9 Dream   \n",
       "\n",
       "            performer  time_on_chart  consecutive_weeks  worst_position  \\\n",
       "0  Young And Restless             15               14.0              91   \n",
       "1         Isaac Hayes              9                8.0              72   \n",
       "2         Goody Goody              5                4.0              99   \n",
       "3               Nelly             20               19.0              75   \n",
       "4         John Lennon             12               11.0              68   \n",
       "\n",
       "  chart_debut                                             lyrics  num_lyrics  \n",
       "0  1990-05-05  “B” Girls LyricsIntro\\nHey Slim Come here chec...         551  \n",
       "1  1973-12-22  1212 Songs LyricsAAlex Turner  Stuck on the Pu...         857  \n",
       "2  1978-11-18  Lbo3d l’akhar LyricsVerse 1 Omar Cravate\\n\\nBa...         577  \n",
       "3  2001-10-20  1 LyricsIntro\\nUh uh uh\\nI just gotta bring it...         723  \n",
       "4  1974-12-21  9 Dream LyricsVerse 1\\nSo long ago\\nWas it in ...         206  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7adc4dc-b7d4-4cb7-a951-c4939591edef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>roberta_neg</th>\n",
       "      <th>roberta_neu</th>\n",
       "      <th>roberta_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\"B\" GirlsYoung And Restless</th>\n",
       "      <td>0.017</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.635587</td>\n",
       "      <td>0.296133</td>\n",
       "      <td>0.06828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"Joy\" Pt. IIsaac Hayes</th>\n",
       "      <td>0.113</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.110</td>\n",
       "      <td>-0.2103</td>\n",
       "      <td>0.635587</td>\n",
       "      <td>0.296133</td>\n",
       "      <td>0.06828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#1 Dee JayGoody Goody</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>0.635587</td>\n",
       "      <td>0.296133</td>\n",
       "      <td>0.06828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#1Nelly</th>\n",
       "      <td>0.114</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-0.1135</td>\n",
       "      <td>0.635587</td>\n",
       "      <td>0.296133</td>\n",
       "      <td>0.06828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#9 DreamJohn Lennon</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.9124</td>\n",
       "      <td>0.635587</td>\n",
       "      <td>0.296133</td>\n",
       "      <td>0.06828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             vader_neg  vader_neu  vader_pos  vader_compound  \\\n",
       "\"B\" GirlsYoung And Restless      0.017      0.918      0.065          0.9706   \n",
       "\"Joy\" Pt. IIsaac Hayes           0.113      0.776      0.110         -0.2103   \n",
       "#1 Dee JayGoody Goody            0.024      0.929      0.048          0.8957   \n",
       "#1Nelly                          0.114      0.759      0.127         -0.1135   \n",
       "#9 DreamJohn Lennon              0.012      0.893      0.095          0.9124   \n",
       "\n",
       "                             roberta_neg  roberta_neu  roberta_pos  \n",
       "\"B\" GirlsYoung And Restless     0.635587     0.296133      0.06828  \n",
       "\"Joy\" Pt. IIsaac Hayes          0.635587     0.296133      0.06828  \n",
       "#1 Dee JayGoody Goody           0.635587     0.296133      0.06828  \n",
       "#1Nelly                         0.635587     0.296133      0.06828  \n",
       "#9 DreamJohn Lennon             0.635587     0.296133      0.06828  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23b89516-dc21-491f-b54b-ed684e4e26c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentiment_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path \n\u001b[1;32m      3\u001b[0m filepath \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/nltk_roberta_lyric_sentiment.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[0;32m----> 4\u001b[0m \u001b[43msentiment_df\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(filepath)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentiment_df' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path \n",
    "\n",
    "filepath = Path('./data/nltk_roberta_lyric_sentiment.csv')  \n",
    "sentiment_df.to_csv(filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
